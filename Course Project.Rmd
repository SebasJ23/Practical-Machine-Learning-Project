---
title: "Practical Machine Learning Course Project"
output: 
  html_document:
    keep_md: true
---

## Overview

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement, a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, the goal is to build a machine learning algorithm to predict activity quality from activity monitors and apply that algorithm to 20 test cases.

```{r set_up, results = "hide"}
for (package in c("caret", "doMC", "knitr", "xtable")) {
    if (!(require(package, character.only = TRUE, quietly = TRUE))) {
        install.packages(package)
        library(package, character.only = TRUE)
    }
}

options(xtable.comment = FALSE)
options(scipen = 5)
```



## Getting and reading the data

The data will be downloaded and saved in the working directory and then it will be read into R. The data is divided into a training dataset and a testing dataset. The first set will be used to build the machine learning algorithm and the second contains the 20 test cases that need to be predicted for the assignment.

```{r download_and_reading, results = "hold"}
# Downloading data
urlTraining <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
urlTesting <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
fileTraining <- "pml-training.csv"
fileTesting <- "pml-testing.csv"
if (!file.exists(fileTraining)) {
    download.file(urlTraining, fileTraining, method = "curl")
}
if (!file.exists(fileTesting)) {
    download.file(urlTesting, fileTesting, method = "curl")
}

# Reading data
training <- read.csv("pml-training.csv")
testing <- read.csv("pml-testing.csv")

# Quick look at the data
dim(training)
dim(testing)
head(training)[1:10]
```

Both datasets have `r dim(training)[2]` variables. In order to build a good machine learning algorithm, the number of variables (features) will be reduced.

## Data cleaning and data partition

The variables that should be eliminated are those with many missing values and those with zero or near zero variability, because they do not add anything to the model. The first variable will also be discarded because it contains only the observation number.

```{r subsetting_data}
# Remove variables where more than half its observations are missing values
index <- which(colMeans(is.na(training)) > 0.5)
subTraining <- training[,-index]

# Remove variables with near zero variance and first column, which is just the row number
index2 <- nearZeroVar(subTraining)
subdata <- subTraining[,-c(1,index2)]
dim(subdata)
```

By removing the initial column (`r 1` variable), the variables with more than half its values being NAs (`r length(index)` variables) and the variables with near zero variation (`r length(index2)` variables), the number of features was reduced from `r dim(training)[2]` to `r dim(subdata)[2]`.

Next, the cleaned training set is divided into `trainData` (`r 60`% of the observations) that will be used to build the algorithm and `validationData` (`r 40`%) that will be used to estimate the out of sample error.

```{r data_partition}
set.seed(123)
indexPart <- createDataPartition(y = subdata$classe, p = 0.6, list = FALSE)
trainData <- subdata[indexPart,]
validationData <- subdata[-indexPart,]
```



## Fitting the models

Different models will be fitted and then one of them will be chosen based on accuracy. Since these computations can be time-consuming, particularly for random forest and boosting, parallelization will be used to decrease the time it takes to build the model. For each model, 10-fold cross-validation will be done, except for random forest, in which case 5-fold cross-validation will be done in order to decrease the time taken to build the model.

```{r set_parallel_and_fit_models, results = "hide", message = FALSE, warning = FALSE}
# Set up parallelization
nCores <- detectCores()
registerDoMC(cores = nCores)

# Fitting models
modelRF <- train(classe ~ ., data = trainData, trControl = trainControl(method = "cv", number = 5),
                 method = "rf") # Random Forest
modelBoost <- train(classe ~ ., data = trainData, trControl = trainControl(method = "cv", number = 10),
                 method = "gbm") # Boosting
modelTrees <- train(classe ~ ., data = trainData, trControl = trainControl(method = "cv", number = 10),
                    method = "rpart") # Classification trees
modelLDA <- train(classe ~ ., data = trainData, trControl = trainControl(method = "cv", number = 10),
                    method = "lda") # Linear Discriminant Analysis
```

```{r model_accuracy_table, results = "asis"}
accRF <- modelRF$results[2,2]
accBoost <- modelBoost$results[9,5]
accTrees <- modelTrees$results[1,2]
accLDA <- as.numeric(modelLDA$results[2])
values <- c(accRF, accBoost, accTrees, accLDA)
rows <- c("Random Forest", "Boosting", "Classification Trees", "Linear Discriminat Analysis")
tab <- data.frame(rows, round(values, 5))
names(tab) <- c("Model", "Accuracy")

print(xtable(tab, digits = c(0,0,5), align = c("l", "l", "r")), type = "html", include.rownames = FALSE,
      html.table.attributes = "align = 'center'")
```

<br>

The greatest accuracy was obtained with the random forest model. Thus, this model will be used for predictions. As for the other models, boosting had accuracy almost equal to that of random forest and it could be used as well. Linear discriminant analysis performed well, but it is a sub-optimal choice. Classification trees performed poorly.


## Validation and out of sample error

Before proceeding with the predictions for the test cases, it is important to calculate the performance of the model with a different dataset. To do this, the validationData will be used to calculate the confusion matrix and the out of sample error for the model.

```{r confusion_matrix}
# Confusion matrix
confusionMatrix(validationData$classe, predict(modelRF, newdata = validationData))
```

The model had a high accuracy of `r round(as.numeric(confusionMatrix(validationData$classe, predict(modelRF, newdata = validationData))$overall[1]), 6)` or `r paste(round(as.numeric(confusionMatrix(validationData$classe, predict(modelRF, newdata = validationData))$overall[1]), 6) * 100, "%", sep = "")`.

```{r out:of_sample_error}
# Out of sample error
outSamErr <- 1- as.numeric(confusionMatrix(validationData$classe, predict(modelRF, newdata = validationData))$overall[1])
```

Therefore, the out of sample error for the model is `r round(outSamErr, 6)` or `r paste(round(outSamErr, 6) * 100, "%", sep = "")`.


## Prediction of test cases

Based on the random forest model, the activities predicted for the 20 test cases in the testing dataset are predicted to be:

```{r prediction}
predict(modelRF, newdata = testing)
```



## Additional Information

### Where to get the data?
All the data used in this project was obtained from the Weight Lifting Exercises Dataset, part of the [Human Activity Recognition] [1] project (1). The data can be downloaded at:

- [Training dataset] [2]

- [Testing dataset] [3]

[1]: http://groupware.les.inf.puc-rio.br/har "Human Activity Recognition website"

[2]: https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv "Training dataset"

[3]: https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv "Testing dataset"



### Bibliography

1. Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.



### R Session Information

```{r session_info}
sessionInfo()
```

